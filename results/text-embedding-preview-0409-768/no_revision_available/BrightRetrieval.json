{
    "dataset_revision": "a75a0eb483f6a5233a6efc2d63d71540a4443dfb",
    "evaluation_time": 0,
    "kg_co2_emissions": null,
    "mteb_version": "1.12.79",
    "scores": {
        "standard": [
            {
                "hf_subset": "earth_science",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.34385,
                "ndcg_at_1": 0.35345,
                "ndcg_at_5": 0.32525,
                "ndcg_at_10": 0.34385,
                "ndcg_at_25": 0.38404,
                "ndcg_at_50": 0.39616,
                "ndcg_at_100": 0.41521,
                "map_at_1": 0.16384,
                "map_at_5": 0.26019,
                "map_at_10": 0.27834,
                "map_at_25": 0.29336,
                "map_at_50": 0.29688,
                "map_at_100": 0.30006,
                "Recall_at_1": 0.16384,
                "Recall_at_5": 0.31434,
                "Recall_at_10": 0.36874,
                "Recall_at_25": 0.48336,
                "Recall_at_50": 0.51735,
                "Recall_at_100": 0.58732,
                "precision_at_1": 0.35345,
                "precision_at_5": 0.18276,
                "precision_at_10": 0.12241,
                "precision_at_25": 0.06966,
                "precision_at_50": 0.03966,
                "precision_at_100": 0.02388,
                "mrr": 0.43865
            },
            {
                "hf_subset": "leetcode",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.29644,
                "ndcg_at_1": 0.30986,
                "ndcg_at_5": 0.27473,
                "ndcg_at_10": 0.29644,
                "ndcg_at_25": 0.32959,
                "ndcg_at_50": 0.34723,
                "ndcg_at_100": 0.36361,
                "map_at_1": 0.16878,
                "map_at_5": 0.23643,
                "map_at_10": 0.24664,
                "map_at_25": 0.25662,
                "map_at_50": 0.25975,
                "map_at_100": 0.26138,
                "Recall_at_1": 0.16878,
                "Recall_at_5": 0.27958,
                "Recall_at_10": 0.33462,
                "Recall_at_25": 0.45458,
                "Recall_at_50": 0.53521,
                "Recall_at_100": 0.62523,
                "precision_at_1": 0.30986,
                "precision_at_5": 0.1169,
                "precision_at_10": 0.06901,
                "precision_at_25": 0.03549,
                "precision_at_50": 0.02042,
                "precision_at_100": 0.01169,
                "mrr": 0.37237
            },
            {
                "hf_subset": "theoremqa_questions",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.21512,
                "ndcg_at_1": 0.20976,
                "ndcg_at_5": 0.20231,
                "ndcg_at_10": 0.21512,
                "ndcg_at_25": 0.22584,
                "ndcg_at_50": 0.23805,
                "ndcg_at_100": 0.25237,
                "map_at_1": 0.13159,
                "map_at_5": 0.17859,
                "map_at_10": 0.1856,
                "map_at_25": 0.18931,
                "map_at_50": 0.19134,
                "map_at_100": 0.19265,
                "Recall_at_1": 0.13159,
                "Recall_at_5": 0.20736,
                "Recall_at_10": 0.23988,
                "Recall_at_25": 0.27769,
                "Recall_at_50": 0.33053,
                "Recall_at_100": 0.40619,
                "precision_at_1": 0.20976,
                "precision_at_5": 0.08098,
                "precision_at_10": 0.0478,
                "precision_at_25": 0.02166,
                "precision_at_50": 0.01288,
                "precision_at_100": 0.0079,
                "mrr": 0.25465
            },
            {
                "hf_subset": "aops",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.09327,
                "ndcg_at_1": 0.10811,
                "ndcg_at_5": 0.09195,
                "ndcg_at_10": 0.09327,
                "ndcg_at_25": 0.1112,
                "ndcg_at_50": 0.13255,
                "ndcg_at_100": 0.15554,
                "map_at_1": 0.02124,
                "map_at_5": 0.05373,
                "map_at_10": 0.06079,
                "map_at_25": 0.06556,
                "map_at_50": 0.06887,
                "map_at_100": 0.07173,
                "Recall_at_1": 0.02124,
                "Recall_at_5": 0.07625,
                "Recall_at_10": 0.10371,
                "Recall_at_25": 0.15541,
                "Recall_at_50": 0.22657,
                "Recall_at_100": 0.31505,
                "precision_at_1": 0.10811,
                "precision_at_5": 0.07748,
                "precision_at_10": 0.04955,
                "precision_at_25": 0.02775,
                "precision_at_50": 0.01982,
                "precision_at_100": 0.01405,
                "mrr": 0.15886
            },
            {
                "hf_subset": "sustainable_living",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.1725,
                "ndcg_at_1": 0.11111,
                "ndcg_at_5": 0.14785,
                "ndcg_at_10": 0.1725,
                "ndcg_at_25": 0.20864,
                "ndcg_at_50": 0.23667,
                "ndcg_at_100": 0.27178,
                "map_at_1": 0.04178,
                "map_at_5": 0.0908,
                "map_at_10": 0.1106,
                "map_at_25": 0.12536,
                "map_at_50": 0.13227,
                "map_at_100": 0.13785,
                "Recall_at_1": 0.04178,
                "Recall_at_5": 0.16961,
                "Recall_at_10": 0.23722,
                "Recall_at_25": 0.34627,
                "Recall_at_50": 0.44453,
                "Recall_at_100": 0.58963,
                "precision_at_1": 0.11111,
                "precision_at_5": 0.09815,
                "precision_at_10": 0.0787,
                "precision_at_25": 0.05074,
                "precision_at_50": 0.03444,
                "precision_at_100": 0.02435,
                "mrr": 0.21856
            },
            {
                "hf_subset": "pony",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.03589,
                "ndcg_at_1": 0.03571,
                "ndcg_at_5": 0.03715,
                "ndcg_at_10": 0.03589,
                "ndcg_at_25": 0.04589,
                "ndcg_at_50": 0.06423,
                "ndcg_at_100": 0.08415,
                "map_at_1": 0.00199,
                "map_at_5": 0.00506,
                "map_at_10": 0.00628,
                "map_at_25": 0.00929,
                "map_at_50": 0.01141,
                "map_at_100": 0.01336,
                "Recall_at_1": 0.00199,
                "Recall_at_5": 0.01028,
                "Recall_at_10": 0.01856,
                "Recall_at_25": 0.0562,
                "Recall_at_50": 0.09631,
                "Recall_at_100": 0.13879,
                "precision_at_1": 0.03571,
                "precision_at_5": 0.0375,
                "precision_at_10": 0.03571,
                "precision_at_25": 0.03893,
                "precision_at_50": 0.03339,
                "precision_at_100": 0.02616,
                "mrr": 0.12274
            },
            {
                "hf_subset": "theoremqa_theorems",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.16767,
                "ndcg_at_1": 0.10769,
                "ndcg_at_5": 0.13881,
                "ndcg_at_10": 0.16767,
                "ndcg_at_25": 0.19906,
                "ndcg_at_50": 0.21674,
                "ndcg_at_100": 0.22683,
                "map_at_1": 0.06667,
                "map_at_5": 0.11449,
                "map_at_10": 0.12887,
                "map_at_25": 0.13899,
                "map_at_50": 0.14169,
                "map_at_100": 0.14264,
                "Recall_at_1": 0.06667,
                "Recall_at_5": 0.17692,
                "Recall_at_10": 0.25513,
                "Recall_at_25": 0.3641,
                "Recall_at_50": 0.44359,
                "Recall_at_100": 0.49487,
                "precision_at_1": 0.10769,
                "precision_at_5": 0.06154,
                "precision_at_10": 0.04308,
                "precision_at_25": 0.024,
                "precision_at_50": 0.01477,
                "precision_at_100": 0.00846,
                "mrr": 0.16905
            },
            {
                "hf_subset": "stackoverflow",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.17935,
                "ndcg_at_1": 0.1453,
                "ndcg_at_5": 0.16618,
                "ndcg_at_10": 0.17935,
                "ndcg_at_25": 0.19961,
                "ndcg_at_50": 0.23594,
                "ndcg_at_100": 0.26213,
                "map_at_1": 0.04521,
                "map_at_5": 0.09877,
                "map_at_10": 0.11466,
                "map_at_25": 0.12377,
                "map_at_50": 0.13253,
                "map_at_100": 0.13803,
                "Recall_at_1": 0.04521,
                "Recall_at_5": 0.15675,
                "Recall_at_10": 0.2159,
                "Recall_at_25": 0.28102,
                "Recall_at_50": 0.41207,
                "Recall_at_100": 0.50347,
                "precision_at_1": 0.1453,
                "precision_at_5": 0.11453,
                "precision_at_10": 0.08291,
                "precision_at_25": 0.05231,
                "precision_at_50": 0.03983,
                "precision_at_100": 0.02744,
                "mrr": 0.24601
            },
            {
                "hf_subset": "biology",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.22984,
                "ndcg_at_1": 0.2233,
                "ndcg_at_5": 0.21224,
                "ndcg_at_10": 0.22984,
                "ndcg_at_25": 0.28059,
                "ndcg_at_50": 0.30576,
                "ndcg_at_100": 0.33526,
                "map_at_1": 0.06187,
                "map_at_5": 0.14444,
                "map_at_10": 0.16587,
                "map_at_25": 0.18522,
                "map_at_50": 0.19154,
                "map_at_100": 0.19596,
                "Recall_at_1": 0.06187,
                "Recall_at_5": 0.19906,
                "Recall_at_10": 0.26136,
                "Recall_at_25": 0.41093,
                "Recall_at_50": 0.50001,
                "Recall_at_100": 0.62104,
                "precision_at_1": 0.2233,
                "precision_at_5": 0.14951,
                "precision_at_10": 0.10291,
                "precision_at_25": 0.06175,
                "precision_at_50": 0.03786,
                "precision_at_100": 0.02369,
                "mrr": 0.31717
            },
            {
                "hf_subset": "robotics",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.15978,
                "ndcg_at_1": 0.13861,
                "ndcg_at_5": 0.15017,
                "ndcg_at_10": 0.15978,
                "ndcg_at_25": 0.18502,
                "ndcg_at_50": 0.20475,
                "ndcg_at_100": 0.22354,
                "map_at_1": 0.07551,
                "map_at_5": 0.11018,
                "map_at_10": 0.11761,
                "map_at_25": 0.12805,
                "map_at_50": 0.13209,
                "map_at_100": 0.13469,
                "Recall_at_1": 0.07551,
                "Recall_at_5": 0.14454,
                "Recall_at_10": 0.17738,
                "Recall_at_25": 0.26268,
                "Recall_at_50": 0.33225,
                "Recall_at_100": 0.40559,
                "precision_at_1": 0.13861,
                "precision_at_5": 0.07921,
                "precision_at_10": 0.05644,
                "precision_at_25": 0.03802,
                "precision_at_50": 0.02614,
                "precision_at_100": 0.01752,
                "mrr": 0.21157
            },
            {
                "hf_subset": "economics",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.19503,
                "ndcg_at_1": 0.18447,
                "ndcg_at_5": 0.18824,
                "ndcg_at_10": 0.19503,
                "ndcg_at_25": 0.22567,
                "ndcg_at_50": 0.24477,
                "ndcg_at_100": 0.27073,
                "map_at_1": 0.06385,
                "map_at_5": 0.11052,
                "map_at_10": 0.12166,
                "map_at_25": 0.13936,
                "map_at_50": 0.14826,
                "map_at_100": 0.15488,
                "Recall_at_1": 0.06385,
                "Recall_at_5": 0.16165,
                "Recall_at_10": 0.20624,
                "Recall_at_25": 0.31451,
                "Recall_at_50": 0.4032,
                "Recall_at_100": 0.50804,
                "precision_at_1": 0.18447,
                "precision_at_5": 0.11456,
                "precision_at_10": 0.08932,
                "precision_at_25": 0.07068,
                "precision_at_50": 0.04816,
                "precision_at_100": 0.03369,
                "mrr": 0.25786
            },
            {
                "hf_subset": "psychology",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 0.27864,
                "ndcg_at_1": 0.26733,
                "ndcg_at_5": 0.26182,
                "ndcg_at_10": 0.27864,
                "ndcg_at_25": 0.30703,
                "ndcg_at_50": 0.32835,
                "ndcg_at_100": 0.35831,
                "map_at_1": 0.12191,
                "map_at_5": 0.17951,
                "map_at_10": 0.20237,
                "map_at_25": 0.22599,
                "map_at_50": 0.23244,
                "map_at_100": 0.23709,
                "Recall_at_1": 0.12191,
                "Recall_at_5": 0.23612,
                "Recall_at_10": 0.31401,
                "Recall_at_25": 0.44192,
                "Recall_at_50": 0.52868,
                "Recall_at_100": 0.65694,
                "precision_at_1": 0.26733,
                "precision_at_5": 0.1505,
                "precision_at_10": 0.11386,
                "precision_at_25": 0.07129,
                "precision_at_50": 0.04337,
                "precision_at_100": 0.02743,
                "mrr": 0.3276
            }
        ]
    },
    "task_name": "BrightRetrieval"
}
